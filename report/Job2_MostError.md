# Job2: Most Error in a TimeInterval (that matches injected Regex pattern)

## Description
Breaks the input log files into time intervals. Finds out which interval has the most number of errors.

## Functionality:
### Mapper 1
Mapper Implementation Class: [MostErrorTimeIntervalMapper.scala](../src/main/scala/Mapper/MostErrorTimeIntervalMapper.scala)

1. Using Regular Expression parse the input LogString into following groups - G1: TimeStamp, G2: Context, G3: LogLevel, G4: ClassName, G5: LogMessage.
2. Extract LogLevel from the LogString (Group3)
3. Based on the Time Interval configured in `applications.config` find which time bucket does the log string belong to.
    By default, timeInterval is configured as 5 minutes. So, total time interval is split into 5 minute blocks (Eg. If the logstring has timestamp 12:33:00.342, then it belongs to the time bucket 12:30:00 - starting time of the timebucket)
4. Check for the presence of injected regular expression in the logstring.
5. If LogLevel is Error, and the Log Message matches the injected regular expression, then the output is written to the intermediate file.

### Reducer 1
Reducer Implementation Class: [MostErrorTimeIntervalReducer.scala](../src/main/scala/Reducer/MostErrorTimeIntervalReducer.scala)

1. Input to Reducer will be of the format, example: `key: 12:30:00, values: [1, 1, 1, 1, 1, 1, 1]`
2. Compute the Sum of all the integers in values array.
3. Write timestamp again as key, and the sum of values as final output value, to the reducer output file.

Second Mapper-Reducer Sorts the output generated by previous job in descending order.
### Mapper 2
1. Read the output of Reducer1
2. Parse, Keys and Values. Multiply the value by -1.
3. Swap keys and values, and write to the intermediate output file.

By default hadoop implementation, Combiner sorts the mapper output by keys in ascending order, before passing it to the Reducer. We take advantage of this Combiner implementation, and converting the values to negative. 

### Reducer 2
1. Read Key Value Pairs.
2. Get the Key(Which is an integer), multiply it by -1 again.
3. Swap the Key Value pair again and write it to output, to preserve the original output format.


### Input Files:

Please find the input log files used for testing this Map-Reduce Job here: [InputFiles](./input)

### Result:
This is the output after running the Map-Reduce job on the above mentioned input files.

Output for running the job with following arguments:

```
hadoop jar LogProcessing-MapReduce-assembly-0.1.jar logprocess/input logprocess/mosterror most-error pattern1
```

Result:
```text
2021-10-17 21:45:00,144
2021-10-10 19:40:00,3
2021-10-07 19:40:00,2
2021-10-04 17:55:00,2
```

__Explanation:__
- In the TimeInterval 21:45:00 on 17th October, there were 144 errors in total that matched the provided Regex Pattern. (In this case: Pattern1, wildcard regex)
- The output is sorted in descending order, based on the number of errors in the time intervals.

Check the output file here: [mosterror.csv](./results/mosterror.csv)

<hr/>

[<< Back to Index](README.md)
